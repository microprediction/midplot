{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:11:28.925064Z",
     "start_time": "2024-10-31T21:11:28.887025Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "TODO: Update the lin\n",
    "<a href=\"https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/endersgame/mean_reversion_attacker/mean_reversion_attacker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cover](./docs/cover.jpg)\n",
    "\n",
    "# En garde, attack!\n",
    "\n",
    "Welcome to Mid+One! Dive into the world of martingales and market dynamics.\n",
    "\n",
    "Your challenge: spot tiny shifts in financial time-series, to predict where prices are heading.\n",
    "\n",
    "It's all about spotting patterns in the elusive mid-price.\n",
    "\n",
    "# The goal\n",
    "\n",
    "## Attacking not forecasting!\n",
    "\n",
    "We don't want to forecast the future prices as this is extremely difficult and requires often a lot of computation. What we want is detect a shift in the market dynamics, up or down, that's it! \n",
    "\n",
    "This is a much simpler task and can be done with a simple model. We also need this decision to be computed quickly! Under 20 milliseconds.\n",
    "\n",
    "To be precise, our attacker will consume a univariate sequence of numerical data points $x_1, x_2, \\dots x_t$ and try to exploit deviations from the [martingale property](https://en.wikipedia.org/wiki/Martingale_(probability_theory)), which is to say that we expect the series $x_t$ to satisfy:\n",
    "$$ E[x_{t+k}] \\approx x_t $$\n",
    "roughly. Of course, there's no such thing in this world as a perfect martingale and it is your job to indicate when\n",
    "$$ E[x_{t+k}] > x_t + \\epsilon $$\n",
    "by returning a positive value, or conversely. Here $\\epsilon$ finds interpretation as a trading cost. The attacker will *typically* return `0` meaning that it thinks:\n",
    "$$  x_t - \\epsilon   > E[x_{t+k}] > x_t + \\epsilon $$\n",
    "because trading opportunities are probably on the rare side - though obviously this is problem dependent. The $\\epsilon$ and $k$ (`horizon`) parameters are set [here](https://github.com/microprediction/midone/blob/main/midone/gameconfig.py).\n",
    "\n",
    "## Scoring\n",
    "\n",
    "The scoring is straightforward: it corresponds to the profit of a simple trading strategy: if the model predicts a move up over some short horizon (corresponding to a few seconds at most), the strategy is to buy now and sell at the end of the horizon minus some transaction costs.\n",
    "\n",
    "If we decided to go up at $t$:\n",
    "$$x_{t+k} - x_t - \\epsilon$$\n",
    "and \n",
    "$$x_t - x_{t+k} - \\epsilon$$\n",
    "if we decided to go down at $t$.\n",
    "\n",
    "The case of a move down is symmetric. In most cases, we don't expect the model to predict a move up or down so we will just do nothing.\n",
    "\n",
    "This is an example of detecting three move ups (the green bands, detecting down would show as red bands), with two resulting in a profit and one with a loss:\n",
    "\n",
    "![Profit](./docs/profit.png) \n",
    "\n",
    "# The data\n",
    "\n",
    "This competition is really meant to focus on single streaming series and should be quite agnostic to particular financial instruments. There is a training phase where parameters can be learned on group of similar instruments but overall, we rely on online learning. \n",
    "\n",
    "Let's look right away at some data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Install the crunch CLI\n",
    "- Use the token to get started with data and submission\n",
    "- Setup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:11:50.765282Z",
     "start_time": "2024-10-31T21:11:35.171198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "---\n",
      "Your token seems to have expired or is invalid.\n",
      "\n",
      "Please follow this link to copy and paste your new setup command:\n",
      "https://hub.crunchdao.com/competitions/mid-one/submit\n",
      "\n",
      "If you think that is an error, please contact an administrator.\n",
      "Requirement already satisfied: midone in ./venv/lib/python3.12/site-packages (1.0.4)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from midone) (1.26.4)\n",
      "Requirement already satisfied: river in ./venv/lib/python3.12/site-packages (from midone) (0.21.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from midone) (2.32.3)\n",
      "Requirement already satisfied: statsmodels in ./venv/lib/python3.12/site-packages (from midone) (0.14.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->midone) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->midone) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->midone) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->midone) (2024.8.30)\n",
      "Requirement already satisfied: pandas<3.0,>=2.1 in ./venv/lib/python3.12/site-packages (from river->midone) (2.2.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.12.1 in ./venv/lib/python3.12/site-packages (from river->midone) (1.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in ./venv/lib/python3.12/site-packages (from statsmodels->midone) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.12/site-packages (from statsmodels->midone) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas<3.0,>=2.1->river->midone) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas<3.0,>=2.1->river->midone) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas<3.0,>=2.1->river->midone) (2024.2)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels->midone) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade crunch-cli -q\n",
    "!crunch setup --notebook mid-one cobra --token bff0RrUG5HBNHqQYGVmVCrXvWU4V4Ywgk0qHSYPmV6UvewfDPrmN7Im2FF6JDMtR\n",
    "%pip install --upgrade midone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:12:04.637951Z",
     "start_time": "2024-10-31T21:11:52.965235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded inline runner with module: <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "import crunch\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Timeseries come as streams and you can get many streams, split into `train` and `test` datasets. \n",
    "\n",
    "A stream is sequence of data points represented by a dictionary. The value of the time series is `pt[\"x\"]` where `p` is the point in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:38:21.500871Z",
     "start_time": "2024-10-31T21:38:16.046258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_train.parquet (7049425 bytes)\n",
      "data/X_train.parquet: already exists, file length match\n",
      "data/X_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_test_reduced.parquet (405611 bytes)\n",
      "data/X_test.parquet: already exists, file length match\n",
      "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_train.parquet (5804278 bytes)\n",
      "data/y_train.parquet: already exists, file length match\n",
      "data/y_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_test_reduced.parquet (411693 bytes)\n",
      "data/y_test.parquet: already exists, file length match\n",
      "data/example_prediction.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/example_prediction_reduced.parquet (59364 bytes)\n",
      "data/example_prediction.parquet: already exists, file length match\n",
      "Loaded 319 training streams and 20 testing streams\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, x_test = crunch.load_streams()\n",
    "\n",
    "print(f\"Loaded {len(x_train)} training streams and {len(x_test)} testing streams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having a peek into the data\n",
    "\n",
    "`midplot` provides a lot of cool features, one is to able to visualize the data.\n",
    "\n",
    "Running over the data sequentially like a live algorithm would do is called `replay`.\n",
    "\n",
    "Let's have a look at the data by replaying the first stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:56:59.020984Z",
     "start_time": "2024-10-31T19:56:54.855307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8d518d3f464671970a42a9e5ecd494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x1221f1fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from midplot import replay\n",
    "replay(x_train[:1], with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the comment about the `infer` function not being defined. Crunch will pick up automatically your attack function once `infer` is define.\n",
    "\n",
    "We only ran the first stream for space. Alternatively, you can specify certain streams like this:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], with_visualization=True)\n",
    "```\n",
    "\n",
    "To only run a subset of the data, you can also specify a `start` and `stop` index:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], start_index=0, stop_index=1000, with_visualization=True)\n",
    "```\n",
    "\n",
    "### Important flexibility\n",
    "\n",
    "`midplot` let's you pass regular iterable of float as well so you don't have to recreate these small dictionaries so you can easily run your algorithm on your own data -- very useful for debugging.\n",
    "\n",
    "This is how you would attack the `log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T18:13:47.273910Z",
     "start_time": "2024-10-29T18:13:47.184934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f59bdb825f424fb959d86d622875d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x123309100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "replay(np.log(range(1, 100)), with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's attack!\n",
    "\n",
    "Underneath, `crunch` requires an `infer` function. The syntax is not completely trivial so `midplot` provides a helper function to do this.\n",
    "\n",
    "We only need to define an Attacker class like the other notebooks.\n",
    "\n",
    "For demo purposes, we will keep a buffer of points and detect a move if the change of price in the second part of the buffer is higher with a threshoold (and will be adjusted) the move in the first part of the buffer.\n",
    "\n",
    "This is a measure of momentum in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:12:14.188028Z",
     "start_time": "2024-10-31T21:12:13.025869Z"
    }
   },
   "outputs": [],
   "source": [
    "from midone import HORIZON, EPSILON, Attacker\n",
    "UP, DOWN, NOTHING = 1., -1., 0.\n",
    "import numpy as np\n",
    "\n",
    "class MomentumAttacker(Attacker):\n",
    "    # We will turn this factor into a hyper-parameter!\n",
    "    factor: float = 2.5\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.buffer = []\n",
    "        self.num_points = 100\n",
    "    def tick_and_predict(self, x: float, horizon: int = HORIZON) -> float:\n",
    "        # Add new value and maintain fixed buffer size\n",
    "        self.buffer.append(x)\n",
    "        if len(self.buffer) > self.num_points:\n",
    "            self.buffer.pop(0)  # Remove oldest value\n",
    "\n",
    "        # Wait until we have enough data\n",
    "        if len(self.buffer) < self.num_points:\n",
    "            return NOTHING\n",
    "\n",
    "        # Split buffer into two halves and calculate change in each half\n",
    "        mid = self.num_points // 2\n",
    "        first_half_change = self.buffer[mid - 1] - self.buffer[0]\n",
    "        second_half_change = self.buffer[-1] - self.buffer[mid]\n",
    "        if np.sign(first_half_change) != np.sign(second_half_change):\n",
    "            return NOTHING\n",
    "        # Compare changes to predict trend\n",
    "        if np.abs(second_half_change) > self.factor * np.abs(first_half_change):\n",
    "            return np.sign(second_half_change)\n",
    "        else:\n",
    "            return NOTHING\n",
    "        \n",
    "from midplot.helpers import wrap\n",
    "infer = wrap(MomentumAttacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to\n",
    "```python\n",
    "\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    yield  # We are ready\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        \n",
    "```\n",
    "\n",
    "## Note: what are the `hyper_parameters`, `with_hyper_parameters_load` and `model_directory_path` for?\n",
    "\n",
    "These parameters are important in the training phase where we want to optimize the parameter and save the optimal parameters which we want to load in the inference phase for the actual submission.\n",
    "\n",
    "It would look like this:\n",
    "```python\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    if hyper_parameters is not None:\n",
    "        # Defined on your model\n",
    "        m.update_from_hyper_parameters(hyper_parameters)\n",
    "    if with_hyper_parameters_load:\n",
    "        # Load from the params for final inference\n",
    "        m.load_params(model_directory_path)\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "```\n",
    "\n",
    "and the train function would look something like that:\n",
    "```python\n",
    "\n",
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    hyper_params = {}\n",
    "    def optimize(hyper_params):\n",
    "        res = replay(streams, hyper_parameters=hyper_params)\n",
    "        return - res.total_score\n",
    "    # Your optimization function\n",
    "    hyper_params = optimize(hyper_params)\n",
    "    # Save the parameters\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the same replay on the first time series\n",
    "\n",
    "The library will automatically call the `infer` function on the data points.\n",
    "\n",
    "Let's also display the scoring for this simple algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:51.747770Z",
     "start_time": "2024-10-29T17:45:49.228209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efc43e308a44d4bae30ba37c514922c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        background…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64dc3b7520e4c62b50ab502c5993421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x127fe9a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay(x_train[:1], stop_index=500, with_accounting_visualizer=True, with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "\n",
    "On the last replay, you can click on the graph and will select some points of the time series. This let's you select simple case where you would like your algorithm to pick up a move up or down or do nothing.\n",
    "\n",
    "This can be very useful to constraints your training to some behavior. Will do some semi-supervised learning in some way.\n",
    "\n",
    "```python\n",
    "get_replay_result().save_selected(UP)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midplot import get_replay_result\n",
    "# Run this to save the scenario\n",
    "# get_replay_result().save_selected(UP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:51.873936Z",
     "start_time": "2024-10-29T17:45:51.857316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 scenarios\n"
     ]
    }
   ],
   "source": [
    "from midplot import load_scenarios\n",
    "movie = load_scenarios()\n",
    "print(f\"Loaded {len(movie.scenarios)} scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can run all the scenarios like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:52.284325Z",
     "start_time": "2024-10-29T17:45:51.991079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6688bec96749258ca6e35848f11a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        background…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe0a6f307ad4edab5dfb1d02397ab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x12784eab0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from midplot.replay import load_scenarios\n",
    "\n",
    "movie = load_scenarios()\n",
    "\n",
    "replay(movie.streams(), horizon=HORIZON, with_accounting_visualizer=True, with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even check that the scenarios are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:52.337469Z",
     "start_time": "2024-10-29T17:45:52.328119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 1 Success 0\n"
     ]
    }
   ],
   "source": [
    "def check_scenarios(threshold=None):\n",
    "    movie = load_scenarios()\n",
    "    r = replay(movie.streams())\n",
    "    return  r.check_scenarios(movie.scenarios, threshold=threshold)\n",
    "\n",
    "ok, checks = check_scenarios(threshold=0.5)\n",
    "print(f\"Failed {len(checks.failed)} Success {len(checks.success)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train!\n",
    "\n",
    "Training here means we will find good values of the parameter of the model, in that case the `factor` parameter.\n",
    "\n",
    "We will use the `nevergrad` package for optimization as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:46:00.409193Z",
     "start_time": "2024-10-29T17:45:52.685968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nevergrad -q\n",
    "import nevergrad as ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:54:29.075621Z",
     "start_time": "2024-10-29T17:54:29.059808Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "    \n",
    "def save_param(filename: str, factor: float):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(json.dumps({\"factor\": factor}))\n",
    "            \n",
    "def load_from_param(filename: str) -> MomentumAttacker:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        factor = float(data[\"factor\"])\n",
    "        m = MomentumAttacker()\n",
    "        m.factor = factor\n",
    "        return m\n",
    "            \n",
    "attacker = MomentumAttacker()\n",
    "attacker.factor = 2.7\n",
    "save_param('params.json', attacker.factor)\n",
    "attacker = load_from_param('params.json')\n",
    "assert attacker.factor == 2.7    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this save/load mechanism, we can now build a simple optimizer which we will use for the train function.\n",
    "\n",
    "But first, we need to tweak the `infer` function to load this hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:53:26.898588Z",
     "start_time": "2024-10-29T17:53:26.892737Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Any\n",
    "def infer(\n",
    "        stream: Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    if hyper_parameters is not None:\n",
    "        m.factor = hyper_parameters \n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick_and_predict(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T18:01:49.235537Z",
     "start_time": "2024-10-29T18:01:49.001106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with factor=1.25 -> 32.50307692310352\n",
      "Score with factor=1.052143659185795 -> 37.743269230794986\n",
      "Score with factor=2.268618244160313 -> 29.022692307707842\n",
      "Score with factor=1.6389814731428825 -> 21.834807692328546\n",
      "Score with factor=1.8925258161805205 -> 20.69000000001092\n",
      "Score with factor=2.0286721014347027 -> 25.012692307706025\n",
      "Score with factor=1.7075720729998114 -> 28.549615384629803\n",
      "Score with factor=1.0501602323044557 -> 37.743269230794986\n",
      "Score with factor=1.7013677838452588 -> 27.777884615399316\n",
      "Score with factor=1.18856787696814 -> 28.793269230793165\n",
      "Optimal factor 1.0501602323044557\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Iterable\n",
    "import os\n",
    "\n",
    "def train(\n",
    "        streams: List[Iterable[dict]],\n",
    "        model_directory_path: str = \".\"):\n",
    "    factor = ng.p.Scalar(init=1.25, lower=1., upper=3.)\n",
    "    parametrization = ng.p.Instrumentation(factor)\n",
    "    optimizer = ng.optimizers.OnePlusOne(parametrization=parametrization, budget=10)\n",
    "\n",
    "    # Define the objective function that we want to minimize\n",
    "    def objective(factor_value):\n",
    "        # To go faster, only subset of data\n",
    "        r = replay(streams, only_stream_ids=[1, 2], stop_index=500, hyper_parameters=factor_value)\n",
    "        print(f\"Score with factor={factor_value} -> {r.total_score}\")\n",
    "        return - r.total_score\n",
    "\n",
    "    # Run the optimization\n",
    "    recommendation = optimizer.minimize(objective)\n",
    "    # Get the optimal factor value\n",
    "    optimal_factor = recommendation[0].value[0]\n",
    "    print(\"Optimal factor\", optimal_factor)\n",
    "    save_param(os.path.join(model_directory_path, \"params.json\"), optimal_factor)\n",
    "    \n",
    "# We run the optimizer\n",
    "train(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finish the proper version of `infer` by adding the loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T18:02:11.004329Z",
     "start_time": "2024-10-29T18:02:05.440942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742d77200d464aa8b485e851bef1dec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        background…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb1a5fe37d341cca69d7134297a3055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x13b545520>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(\n",
    "        stream: Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    \n",
    "    if with_hyper_parameters_load:\n",
    "        m = load_from_param(os.path.join(model_directory_path, \"params.json\"))\n",
    "\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick_and_predict(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        \n",
    "replay(streams=x_train, only_stream_ids=[5], stop_index=1000, with_visualization=True, with_accounting_visualizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we are done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring double-check\n",
    "\n",
    "Let's double check that the scoring is consistent between the attacker and the backend.\n",
    "\n",
    "For that, we will use the `crunch.test()` and use the testing function written that mimicks the backend computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:53:36.154547Z",
     "start_time": "2024-10-31T21:53:32.616753Z"
    }
   },
   "outputs": [],
   "source": [
    "from midplot import replay\n",
    "\n",
    "res = replay(x_test, horizon=HORIZON, epsilon=EPSILON, with_hyper_parameters_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:39:07.335396Z",
     "start_time": "2024-10-31T21:38:55.930442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:14:35 no forbidden library found\n",
      "18:14:35 \n",
      "18:14:35 started\n",
      "18:14:35 running local test\n",
      "18:14:35 internet access isn't restricted, no check will be done\n",
      "18:14:35 \n",
      "18:14:39 starting stream loop...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_train.parquet (7049425 bytes)\n",
      "data/X_train.parquet: already exists, file length match\n",
      "data/X_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_test_reduced.parquet (405611 bytes)\n",
      "data/X_test.parquet: already exists, file length match\n",
      "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_train.parquet (5804278 bytes)\n",
      "data/y_train.parquet: already exists, file length match\n",
      "data/y_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_test_reduced.parquet (411693 bytes)\n",
      "data/y_test.parquet: already exists, file length match\n",
      "data/example_prediction.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/example_prediction_reduced.parquet (59364 bytes)\n",
      "data/example_prediction.parquet: already exists, file length match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:14:39 call: train - stream.len=319\n",
      "18:14:39 looping stream=`stream_0` (1/20)\n",
      "18:14:39 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_1` (2/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_10` (3/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_11` (4/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_12` (5/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_13` (6/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_14` (7/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_15` (8/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:40 looping stream=`stream_16` (9/20)\n",
      "18:14:40 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_17` (10/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_18` (11/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_19` (12/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_2` (13/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_3` (14/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_4` (15/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:41 looping stream=`stream_5` (16/20)\n",
      "18:14:41 call: infer (1/1)\n",
      "18:14:42 looping stream=`stream_6` (17/20)\n",
      "18:14:42 call: infer (1/1)\n",
      "18:14:42 looping stream=`stream_7` (18/20)\n",
      "18:14:42 call: infer (1/1)\n",
      "18:14:42 looping stream=`stream_8` (19/20)\n",
      "18:14:42 call: infer (1/1)\n",
      "18:14:42 looping stream=`stream_9` (20/20)\n",
      "18:14:42 call: infer (1/1)\n",
      "18:14:42 save prediction - path=data/prediction.parquet\n",
      "18:14:43 check prediction - call=columns_name({}) column=`prediction`\n",
      "18:14:43 check prediction - call=nans({}) column=`prediction`\n",
      "18:14:43 check prediction - call=moons({}) column=`prediction`\n",
      "18:14:43 check prediction - call=ids({}) column=`prediction`\n",
      "18:14:43 prediction is valid\n",
      "18:14:43 ended\n",
      "18:14:43 duration - time=00:00:07\n",
      "18:14:43 memory - before=\"487.97 MB\" after=\"752.86 MB\" consumed=\"264.89 MB\"\n"
     ]
    }
   ],
   "source": [
    "from midplot.test import  pnl\n",
    "def train():\n",
    "    pass\n",
    "predictions = crunch.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T21:53:43.165965Z",
     "start_time": "2024-10-31T21:53:41.769010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PnL: -146.31970620566835 and with the test function: -146.58720620566876\n"
     ]
    }
   ],
   "source": [
    "res_check = pnl(predictions, x_test, HORIZON, EPSILON)\n",
    "print(f\"With PnL: {res.total_score} and with the test function: {res_check.total_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6keI5dhzzA91GFxncpHCk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
