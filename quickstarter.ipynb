{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "TODO: Update the lin\n",
    "<a href=\"https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/endersgame/mean_reversion_attacker/mean_reversion_attacker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cover](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/mid-one/cover.jpg)\n",
    "\n",
    "# En garde, attack!\n",
    "\n",
    "Welcome to Mid+One! Dive into the world of martingales and market dynamics.\n",
    "\n",
    "Your challenge: spot tiny shifts in financial time-series, to predict where prices are heading.\n",
    "\n",
    "It's all about spotting patterns in the elusive mid-price.\n",
    "\n",
    "# The goal\n",
    "\n",
    "## Attacking not forecasting!\n",
    "\n",
    "We don't want to forecast the future prices as this is extremely difficult and requires often a lot of computation. What we want is detect a shift in the market dynamics, up or down, that's it! \n",
    "\n",
    "This is a much simpler task and can be done with a simple model. We also need this decision to be computed quickly! Under 20 milliseconds.\n",
    "\n",
    "To be precise, our attacker will consume a univariate sequence of numerical data points $x_1, x_2, \\dots x_t$ and try to exploit deviations from the [martingale property](https://en.wikipedia.org/wiki/Martingale_(probability_theory)), which is to say that we expect the series $x_t$ to satisfy:\n",
    "$$ E[x_{t+k}] \\approx x_t $$\n",
    "roughly. Of course, there's no such thing in this world as a perfect martingale and it is your job to indicate when\n",
    "$$ E[x_{t+k}] > x_t + \\epsilon $$\n",
    "by returning a positive value, or conversely. Here $\\epsilon$ finds interpretation as a trading cost. The attacker will *typically* return `0` meaning that it thinks:\n",
    "$$  x_t - \\epsilon   > E[x_{t+k}] > x_t + \\epsilon $$\n",
    "because trading opportunities are probably on the rare side - though obviously this is problem dependent. The $\\epsilon$ and $k$ (`horizon`) parameters are set [here](https://github.com/microprediction/midone/blob/main/midone/gameconfig.py).\n",
    "\n",
    "## Scoring\n",
    "\n",
    "The scoring is straightforward: it corresponds to the profit of a simple trading strategy: if the model predicts a move up over some short horizon (corresponding to a few seconds at most), the strategy is to buy now and sell at the end of the horizon minus some transaction costs.\n",
    "\n",
    "If we decided to go up at $t$:\n",
    "$$x_{t+k} - x_t - \\epsilon$$\n",
    "and \n",
    "$$x_t - x_{t+k} - \\epsilon$$\n",
    "if we decided to go down at $t$.\n",
    "\n",
    "The case of a move down is symmetric. In most cases, we don't expect the model to predict a move up or down so we will just do nothing.\n",
    "\n",
    "This is an example of detecting three move ups (the green bands, detecting down would show as red bands), with two resulting in a profit and one with a loss:\n",
    "\n",
    "![Profit](docs/profit.png) \n",
    "\n",
    "# The data\n",
    "\n",
    "This competition is really meant to focus on single streaming series and should be quite agnostic to particular financial instruments. There is a training phase where parameters can be learned on group of similar instruments but overall, we rely on online learning. \n",
    "\n",
    "Let's look right away at some data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Install the crunch CLI\n",
    "- Use the token to get started with data and submission\n",
    "- Setup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:26.102038Z",
     "start_time": "2024-10-28T15:09:16.424264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\r\n",
      "---\r\n",
      "Your token seems to have expired or is invalid.\r\n",
      "\r\n",
      "Please follow this link to copy and paste your new setup command:\r\n",
      "https://hub.crunchdao.com/competitions/mid-one/submit\r\n",
      "\r\n",
      "If you think that is an error, please contact an administrator.\r\n",
      "loaded inline runner with module: <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import signm\n",
    "%pip install --upgrade crunch-cli -q\n",
    "!crunch setup --notebook mid-one cobra --token bff0RrUG5HBNHqQYGVmVCrXvWU4V4Ywgk0qHSYPmV6UvewfDPrmN7Im2FF6JDMtR\n",
    "\n",
    "import crunch\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Timeseries come as streams and you can get many streams, split into `train` and `test` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:33.123255Z",
     "start_time": "2024-10-28T15:09:27.761206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download data/X_train.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_train.parquet (7049425 bytes)\n",
      "already exists: file length match\n",
      "download data/y_train.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_train.parquet (5804278 bytes)\n",
      "already exists: file length match\n",
      "download data/X_test.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_test_reduced.parquet (405611 bytes)\n",
      "already exists: file length match\n",
      "download data/y_test.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_test_reduced.parquet (411693 bytes)\n",
      "already exists: file length match\n",
      "download data/example_prediction.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/example_prediction_reduced.parquet (59364 bytes)\n",
      "already exists: file length match\n",
      "Loaded 319 training streams and 20 testing streams\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, x_test = crunch.load_streams()\n",
    "\n",
    "print(f\"Loaded {len(x_train)} training streams and {len(x_test)} testing streams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having a peek into the data\n",
    "\n",
    "`midplot` provides a lot of cool feature, one is to able to visualize the data. Let's have a look at the first stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:39.746951Z",
     "start_time": "2024-10-28T15:09:35.232896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc201d2501e4b9884bc2b8eff4ce6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x11a006f30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from midplot import replay\n",
    "replay(x_train[:1], with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify certain streams like this:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], with_visualization=True)\n",
    "```\n",
    "\n",
    "To only run a subset of the data, you can also specify a `start` and `stop` index:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], start_index=0, stop_index=1000, with_visualization=True)\n",
    "```\n",
    "\n",
    "A stream is sequence of data points represented by a dictionary. The value of the time series is `pt[\"x\"]`. `midplot` let's you pass regular iterable of float so you can easily run your algorithm on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:10:26.043031Z",
     "start_time": "2024-10-28T15:10:25.959310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00456c1e32984cdbb7eb77d808c4f8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x11eeb2000>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "replay(np.log(range(1, 100)), with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's attack!\n",
    "\n",
    "Underneath, `crunch` requires an `infer` function. The syntax is not completely trivial so `midplot` provides a helper function to do this.\n",
    "\n",
    "We only need to define an Attacker class like the other notebooks. For demo purposes, we will keep a buffer of points and detect a move if the change of price in the second part of the buffer is more than five times (and will be adjusted) the move in the first part of the buffer. This is a measure of momentum in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midone import HORIZON, EPSILON, Attacker\n",
    "UP, DOWN, NOTHING = 1., -1., 0.\n",
    "\n",
    "class MomentumAttacker(Attacker):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.buffer = []\n",
    "        self.num_points = 100\n",
    "    def tick_and_predict(self, new_value: float, horizon: int = HORIZON) -> float:\n",
    "        # Add new value and maintain fixed buffer size\n",
    "        self.buffer.append(new_value)\n",
    "        if len(self.buffer) > self.num_points:\n",
    "            self.buffer.pop(0)  # Remove oldest value\n",
    "\n",
    "        # Wait until we have enough data\n",
    "        if len(self.buffer) < self.num_points:\n",
    "            return NOTHING\n",
    "\n",
    "        # Split buffer into two halves and calculate change in each half\n",
    "        mid = self.num_points // 2\n",
    "        first_half_change = self.buffer[mid - 1] - self.buffer[0]\n",
    "        second_half_change = self.buffer[-1] - self.buffer[mid]\n",
    "        if np.sign(first_half_change) != np.sign(second_half_change):\n",
    "            return NOTHING\n",
    "        # Compare changes to predict trend\n",
    "        if np.abs(second_half_change) > 5 * np.abs(first_half_change):\n",
    "            return np.sign(second_half_change)\n",
    "        else:\n",
    "            return NOTHING\n",
    "        \n",
    "from midplot.helpers import wrap\n",
    "infer = wrap(MomentumAttacker)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is equivalent to\n",
    "```python\n",
    "\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    yield  # We are ready\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        \n",
    "```\n",
    "\n",
    "## Note: what are the `hyper_parameters`, `with_hyper_parameters_load` and `model_directory_path` for?\n",
    "\n",
    "These parameters are important in the training phase where we want to optimize the parameter and save the optimal parameters which we want to load in the inference phase for the actual submission.\n",
    "\n",
    "It would look like this:\n",
    "```python\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    if hyper_parameters is not None:\n",
    "        # Defined on your model\n",
    "        m.update_from_hyper_parameters(hyper_parameters)\n",
    "    if with_hyper_parameters_load:\n",
    "        # Load from the params for final inference\n",
    "        m.load_params(model_directory_path)\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "```\n",
    "\n",
    "and the train function would look something like that:\n",
    "```python\n",
    "\n",
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    hyper_params = {}\n",
    "    def optimize(hyper_params):\n",
    "        res = replay(streams, hyper_parameters=hyper_params)\n",
    "        return - res.total_score\n",
    "    # Your optimization function\n",
    "    hyper_params = optimize(hyper_params)\n",
    "    # Save the parameters\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the same replay on the first time series\n",
    "\n",
    "The library will automatically call the `infer` function on the data points.\n",
    "\n",
    "Let's also display the scoring for this simple algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:12:33.516447Z",
     "start_time": "2024-10-28T15:12:31.241115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0665cd4a72b49cdb4572793465de378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        background…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f801a028ce49eaa4383e219263e778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x11f374fb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay(x_train[:1], stop_index=500, with_accounting_visualizer=True, with_visualization=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenarios\n",
    "\n",
    "On the last replay, you can click on the graph and will select some points of the time series. This let's you select simple case where you would like your algorithm to pick up a move up or down or do nothing.\n",
    "\n",
    "This can be very useful to constraints your training to some behavior. Will do some semi-supervised learning in some way.\n",
    "\n",
    "```python\n",
    "get_replay_result().save_selected(UP)\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from midplot import get_replay_result\n",
    "get_replay_result().save_selected(UP)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T17:26:13.193217Z",
     "start_time": "2024-10-28T17:26:13.179939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from midplot import load_scenarios\n",
    "movie = load_scenarios()\n",
    "print(f\"Loaded {len(movie.scenarios)} scenarios\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 scenarios\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "You can run all the scenarios like this:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T17:27:01.843858Z",
     "start_time": "2024-10-28T17:27:01.558081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from midplot.replay import load_scenarios\n",
    "\n",
    "movie = load_scenarios()\n",
    "\n",
    "replay(movie.streams(), horizon=HORIZON, with_accounting_visualizer=True, with_visualization=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        background…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0383d9a6f67d40a9ab459caa3a589e10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ed1386ac0904ffdbbabcd99ca9ffdf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x11fb578f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "or even check that the scenarios are successful:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T17:28:05.642376Z",
     "start_time": "2024-10-28T17:28:05.620188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def check_scenarios(threshold=None):\n",
    "    movie = load_scenarios()\n",
    "    r = replay(movie.streams())\n",
    "    return  r.check_scenarios(movie.scenarios, threshold=threshold)\n",
    "\n",
    "ok, checks = res.check_scenarios(movie.scenarios, threshold=0.5)\n",
    "print(f\"Failed {len(checks.failed)} Success {len(checks.success)}\")\n",
    "assert ok\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 1 Success 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m ok, checks \u001B[38;5;241m=\u001B[39m res\u001B[38;5;241m.\u001B[39mcheck_scenarios(movie\u001B[38;5;241m.\u001B[39mscenarios, threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(checks\u001B[38;5;241m.\u001B[39mfailed)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Success \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(checks\u001B[38;5;241m.\u001B[39msuccess)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m ok\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS WHERE IT DEPENDS IF I INCLUDE algos FOR THE TRAINING TO BE EASIER OR NOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:38:41.233935Z",
     "start_time": "2024-10-28T12:38:41.204296Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (buffer.py, line 78)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m~/Development/midone/midplot/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3550\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[1;32mIn[5], line 3\u001B[0m\n    from algos.diff import Diff\u001B[0m\n",
      "\u001B[0;36m  File \u001B[0;32m~/Development/midone/midplot/algos/diff.py:1\u001B[0;36m\n\u001B[0;31m    from algos.buffer import Buffer\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m~/Development/midone/midplot/algos/buffer.py:78\u001B[0;36m\u001B[0m\n\u001B[0;31m    return self._buffer + self._recent_data\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "import os\n",
    "from algos.diff import Diff\n",
    "\n",
    "from algos.split import Split\n",
    "from algos.momentum import Momentum\n",
    "from algos.optimize import load_params\n",
    "from typing import Any\n",
    "from midplot import replay, get_replay_result\n",
    "from algos.multi import Detector\n",
    "\n",
    "def get_parameter_file_path(model_directory_path: str):\n",
    "    return os.path.join(model_directory_path, 'resources/params.json')\n",
    "\n",
    "\n",
    "\n",
    "def base_model():\n",
    "    return Detector(Momentum)#, Diff, Split)\n",
    "\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = base_model()\n",
    "\n",
    "    if hyper_parameters is not None:\n",
    "        m.update_models_from_parametrization(hyper_parameters)\n",
    "\n",
    "    if with_hyper_parameters_load:\n",
    "        try:\n",
    "            hyper_parameters = load_params(get_parameter_file_path(model_directory_path))\n",
    "            m.update_models_from_parametrization(hyper_parameters)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    # Signals to the system that your attacker is initialized and ready.\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:38:17.136585Z",
     "start_time": "2024-10-28T12:38:16.824397Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mreplay\u001B[49m(x_train, only_stream_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, stop_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m, horizon\u001B[38;5;241m=\u001B[39mHORIZON, epsilon\u001B[38;5;241m=\u001B[39mEPSILON, with_visualization\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, with_accounting_visualizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitial\u001B[39m\u001B[38;5;124m\"\u001B[39m, res\u001B[38;5;241m.\u001B[39mtotal_score)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'replay' is not defined"
     ]
    }
   ],
   "source": [
    "res = replay(x_train, only_stream_ids=0, stop_index=5000, horizon=HORIZON, epsilon=EPSILON, with_visualization=True, with_accounting_visualizer=True)\n",
    "print(\"Initial\", res.total_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:15:32.732994Z",
     "start_time": "2024-10-25T13:15:32.599392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_parameter_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 73\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;66;03m# return recommendation.value\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizing\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 73\u001B[0m \u001B[43moptimize_multi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[38], line 20\u001B[0m, in \u001B[0;36moptimize_multi\u001B[0;34m(model_directory_path, budget)\u001B[0m\n\u001B[1;32m     18\u001B[0m m \u001B[38;5;241m=\u001B[39m base_model()\n\u001B[1;32m     19\u001B[0m p \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39mcreate_parametrization()\n\u001B[0;32m---> 20\u001B[0m param_file \u001B[38;5;241m=\u001B[39m \u001B[43mget_parameter_file_path\u001B[49m(model_directory_path)\n\u001B[1;32m     22\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m SimpleOptimizer(p)\n\u001B[1;32m     24\u001B[0m movie \u001B[38;5;241m=\u001B[39m load_scenarios()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'get_parameter_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from algos.optimize import SimpleOptimizer, save_params\n",
    "from midplot.replay import load_scenarios\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def check_scenarios(mov, hyper_parameters, threshold=None):\n",
    "    r = replay(mov.streams(), horizon=HORIZON, epsilon=EPSILON, hyper_parameters=hyper_parameters)\n",
    "    return  r.check_scenarios(mov.scenarios, threshold=threshold)\n",
    "\n",
    "\n",
    "def get_stream_ids():\n",
    "    return random.sample(range(0, len(x_train)), 25)\n",
    "\n",
    "MAX_ITERATIONS = 100\n",
    "\n",
    "def optimize_multi(model_directory_path: str = \".\", budget: int = 5):\n",
    "    m = base_model()\n",
    "    p = m.create_parametrization()\n",
    "    param_file = get_parameter_file_path(model_directory_path)\n",
    "    \n",
    "    optimizer = SimpleOptimizer(p)\n",
    "    \n",
    "    movie = load_scenarios()\n",
    "    print(f\"Loaded {len(movie.scenarios)} scenarios\")\n",
    "    \n",
    "    stream_ids = get_stream_ids()\n",
    "    periods = 0\n",
    "    iteration = 0\n",
    "    num_success_scenarios = None\n",
    "    best_score = - np.inf\n",
    "    \n",
    "    with tqdm(total=budget, desc=\"Optimizing\") as pbar:\n",
    "        while periods < budget:\n",
    "            iteration += 1\n",
    "            if iteration > MAX_ITERATIONS:\n",
    "                break\n",
    "            x = optimizer.ask()\n",
    "            _, p = x\n",
    "            if periods % 10 == 0:\n",
    "                # Check scenarios first\n",
    "                threshold = 0.25 if num_success_scenarios is None else num_success_scenarios / len(movie.scenarios)\n",
    "                ok, scen = check_scenarios(movie, p, threshold=threshold)\n",
    "                if not ok:\n",
    "                    print(f\"Failed at scenarios at {threshold}%: {scen}\")\n",
    "                    optimizer.tell(x, - np.inf)\n",
    "                    if iteration > MAX_ITERATIONS:\n",
    "                        raise Exception(\"Could not find a good solution\")\n",
    "                    continue\n",
    "                print(f\"Success at scenarios at {threshold}%: {scen}\")\n",
    "                num_success_scenarios = len(scen.success)\n",
    "            iteration = 0\n",
    "            periods += 1\n",
    "            r = replay(x_train, horizon=HORIZON, epsilon=EPSILON, only_stream_ids=stream_ids, hyper_parameters=p)\n",
    "            # Print the elapsed time\n",
    "            loss = - r.total_score\n",
    "            if -loss > best_score:\n",
    "                best_score = -loss\n",
    "            # Update the progress bar\n",
    "            print(f\"Period {periods} Score {-loss} Best {best_score}\")\n",
    "            pbar.set_postfix(best_score=best_score)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            optimizer.tell(x, loss)\n",
    "\n",
    "            recommendation = optimizer.recommend()\n",
    "            _, p = recommendation\n",
    "            save_params(p, param_file)\n",
    "\n",
    "    # return recommendation.value\n",
    "\n",
    "print(\"Optimizing\")\n",
    "optimize_multi(\".\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpvP8BbRpixH"
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EimzKx0lxo7y",
    "outputId": "2a9184dc-8173-46d1-a809-84168cdfcb0b"
   },
   "outputs": [],
   "source": [
    "predictions = crunch.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gu4daet75Fg"
   },
   "source": [
    "### The `train` function\n",
    "The canonical way to write a training procedure uses `streams` argument and iterates over all data points in all training streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:16:11.184186Z",
     "start_time": "2024-10-25T13:16:11.142701Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPMdvBBD76xG",
    "outputId": "8c1f01a6-52d7-4b86-e2ea-b972da576868"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    optimize_multi(model_directory_path, budget=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:38:57.248831Z",
     "start_time": "2024-10-25T13:38:51.927435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing parameters: Instrumentation(Tuple(),Dict(model_0_alpha=Scalar{Cl(0.01,0.1,b)}[sigma=Scalar{exp=2.03}],model_0_momentum_factor=Scalar{Cl(2,4,b)}[sigma=Scalar{exp=2.03}],model_1_factor=Scalar{Cl(0.5,2.5,b)}[sigma=Scalar{exp=2.03}],model_2_factor=Scalar{Cl(1,2.5,b)}[sigma=Scalar{exp=2.03}])):((), {'model_0_alpha': 0.05, 'model_0_momentum_factor': 3.0, 'model_1_factor': 1.0, 'model_2_factor': 1.5})\n",
      "Loaded 22 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success at scenarios at 0.25%: Success: 11, Failed: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   0%|          | 0/1 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'total_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Here is how you would use it on the training data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstreams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_directory_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresources\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[40], line 9\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(streams, model_directory_path)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\n\u001B[1;32m      6\u001B[0m     streams: typing\u001B[38;5;241m.\u001B[39mList[typing\u001B[38;5;241m.\u001B[39mIterable[\u001B[38;5;28mdict\u001B[39m]],\n\u001B[1;32m      7\u001B[0m     model_directory_path: \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m      8\u001B[0m ):\n\u001B[0;32m----> 9\u001B[0m     \u001B[43moptimize_multi\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_directory_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbudget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[38], line 56\u001B[0m, in \u001B[0;36moptimize_multi\u001B[0;34m(model_directory_path, budget)\u001B[0m\n\u001B[1;32m     54\u001B[0m r \u001B[38;5;241m=\u001B[39m replay(x_train, horizon\u001B[38;5;241m=\u001B[39mHORIZON, epsilon\u001B[38;5;241m=\u001B[39mEPSILON, only_stream_ids\u001B[38;5;241m=\u001B[39mstream_ids, hyper_parameters\u001B[38;5;241m=\u001B[39mp)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Print the elapsed time\u001B[39;00m\n\u001B[0;32m---> 56\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtotal_score\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m-\u001B[39mloss \u001B[38;5;241m>\u001B[39m best_score:\n\u001B[1;32m     58\u001B[0m     best_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mloss\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'total_score'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here is how you would use it on the training data\n",
    "train(\n",
    "    streams=x_train[:1],\n",
    "    model_directory_path=\"resources\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:21:34.522804Z",
     "start_time": "2024-10-25T13:21:29.409304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:21:30 forbidden library: algos\n",
      "09:21:30 \n",
      "09:21:31 started\n",
      "09:21:31 running local test\n",
      "09:21:31 internet access isn't restricted, no check will be done\n",
      "09:21:31 \n",
      "09:21:34 duration - time=00:00:03\n",
      "09:21:34 memory - before=\"207.84 MB\" after=\"208.38 MB\" consumed=\"556.00 KB\"\n",
      "09:21:34 Cancelled!\n"
     ]
    }
   ],
   "source": [
    "predictions = crunch.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandoc in ./venv/lib/python3.12/site-packages (2.4)\n",
      "Requirement already satisfied: plumbum in ./venv/lib/python3.12/site-packages (from pandoc) (1.9.0)\n",
      "Requirement already satisfied: ply in ./venv/lib/python3.12/site-packages (from pandoc) (3.11)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6keI5dhzzA91GFxncpHCk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
